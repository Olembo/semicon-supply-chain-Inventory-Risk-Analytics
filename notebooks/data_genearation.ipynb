{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513b0792",
   "metadata": {},
   "source": [
    "### Step 1: Generate Semiconductor Supplier List\n",
    "1. This script creates a realistic supplier dataset for a semiconductor company.\n",
    "2. Includes: Supplier ID, Name, Country, Tier Level, On-Time Delivery Rating.\n",
    "3. Tier 1 = critical, high-value suppliers; Tier 2 = secondary or less critical.\n",
    "4. Ratings are given as % and will be used later in supplier performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842b1260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier list generated and saved to suppliers.csv\n",
      "  supplier_id              supplier_name        country tier_level  \\\n",
      "0        S001       Nippon Substrate Co.          Japan     Tier 2   \n",
      "1        S002        FormoTech Packaging       Malaysia     Tier 1   \n",
      "2        S003  Taiwan Advanced Materials  United States     Tier 1   \n",
      "3        S004      Korea Probe Solutions          Korea     Tier 1   \n",
      "4        S005    Silicon Precision Works      Singapore     Tier 1   \n",
      "\n",
      "   on_time_rating  \n",
      "0           88.76  \n",
      "1           94.34  \n",
      "2           88.20  \n",
      "3           92.80  \n",
      "4           92.33  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Predefined realistic supplier names (fictional but industry-inspired)\n",
    "supplier_names = [\n",
    "    \"Nippon Substrate Co.\", \"FormoTech Packaging\", \"Taiwan Advanced Materials\",\n",
    "    \"Korea Probe Solutions\", \"Silicon Precision Works\", \"Tokyo WaferTech\",\n",
    "    \"GlobalTest Equipment\", \"Micron Substrates EU\", \"United Semiconductor Parts\",\n",
    "    \"Shenzhen Bonding Supplies\", \"ASE Materials Division\", \"SPIL Components Ltd.\",\n",
    "    \"Hanwa Leadframes\", \"Hitachi Bonding Wires\", \"K&S Precision Tools\",\n",
    "    \"Amkor Assembly Supplies\", \"Infineon Packaging Materials\", \"ST Micro Parts Asia\",\n",
    "    \"Applied Materials Korea\", \"Nanotech Packaging Taiwan\"\n",
    "]\n",
    "\n",
    "# Corresponding realistic supplier countries (aligned with actual IC supply hubs)\n",
    "countries = [\n",
    "    \"Japan\", \"Taiwan\", \"Korea\", \"United States\", \"China\", \"Germany\", \"Singapore\", \"Malaysia\"\n",
    "]\n",
    "\n",
    "# Generate data\n",
    "suppliers_data = []\n",
    "for i, name in enumerate(supplier_names, start=1):\n",
    "    supplier_id = f\"S{i:03d}\"\n",
    "    country = random.choice(countries)\n",
    "    tier_level = random.choices([\"Tier 1\", \"Tier 2\"], weights=[0.6, 0.4])[0]\n",
    "    on_time_rating = round(random.uniform(85, 99), 2)  # percentage\n",
    "    suppliers_data.append([supplier_id, name, country, tier_level, on_time_rating])\n",
    "\n",
    "# Create DataFrame\n",
    "suppliers_df = pd.DataFrame(suppliers_data, columns=[\n",
    "    \"supplier_id\", \"supplier_name\", \"country\", \"tier_level\", \"on_time_rating\"\n",
    "])\n",
    "\n",
    "# Save to CSV for later MySQL loading\n",
    "suppliers_df.to_csv(\"suppliers.csv\", index=False)\n",
    "\n",
    "print(\"Supplier list generated and saved to suppliers.csv\")\n",
    "print(suppliers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757117f4",
   "metadata": {},
   "source": [
    "### Generate BOM Components with Categories, Unit Costs, and Lead Times\n",
    "\n",
    "1. This script creates a realistic Bill of Materials (BOM) for a semiconductor packaging/testing context.\n",
    "2. Fields: component_id, component_name, category, unit_cost_usd, lead_time_days\n",
    "    - Categories reflect real IC packaging/test materials & parts.\n",
    "    - Unit costs and lead times are sampled from realistic ranges per category.\n",
    "    - Output is saved to components.csv for downstream loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf44fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Components BOM generated: 240 rows -> components.csv\n",
      "    component_id                   component_name               category  \\\n",
      "80         C0081             Au Wire Ø0.75mil #13   Bonding Wire (Au/Cu)   \n",
      "129        C0130                     DAF 30µm #19  Die Attach Film/Paste   \n",
      "3          C0004                 300mm Si Wafer 4         Silicon Wafers   \n",
      "205        C0206                    JEDEC Tray 14    Carrier Tapes/Trays   \n",
      "148        C0149   Capillary Underfill UF-180 #18        Underfill/Epoxy   \n",
      "190        C0191  BGA Test Socket 0.4mm pitch #12           Test Sockets   \n",
      "94         C0095            EMC Low-Alpha Grade 4          Mold Compound   \n",
      "88         C0089             Cu Wire Ø0.65mil #21   Bonding Wire (Au/Cu)   \n",
      "\n",
      "     unit_cost_usd  lead_time_days  \n",
      "80            0.40              32  \n",
      "129           5.72              52  \n",
      "3            87.62              77  \n",
      "205           0.07              31  \n",
      "148           8.10              36  \n",
      "190          94.30              42  \n",
      "94            4.63              33  \n",
      "88            0.76              31  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Category specifications: (name, unit_cost_range_usd, lead_time_days_range)\n",
    "CATEGORY_SPECS = [\n",
    "    (\"Silicon Wafers\", (80, 450), (35, 70)),\n",
    "    (\"Organic Substrates\", (0.6, 3.5), (28, 56)),\n",
    "    (\"Leadframes\", (0.05, 0.45), (21, 42)),\n",
    "    (\"Bonding Wire (Au/Cu)\", (0.12, 0.9), (21, 49)),\n",
    "    (\"Mold Compound\", (2.0, 8.0), (28, 56)),\n",
    "    (\"Die Attach Film/Paste\", (4.0, 16.0), (28, 63)),\n",
    "    (\"Underfill/Epoxy\", (3.0, 14.0), (28, 63)),\n",
    "    (\"Solder Balls/Spheres\", (0.01, 0.08), (21, 42)),\n",
    "    (\"Probe Cards\", (2000, 12000), (56, 98)),\n",
    "    (\"Test Sockets\", (60, 380), (35, 77)),\n",
    "    (\"Carrier Tapes/Trays\", (0.03, 0.25), (14, 35)),\n",
    "    (\"Nozzles/Capillaries\", (15, 95), (21, 49)),\n",
    "]\n",
    "\n",
    "# Helper to create realistic component names within each category\n",
    "NAME_TEMPLATES = {\n",
    "    \"Silicon Wafers\": lambda i: f\"200mm Si Wafer {i}\" if i % 2 else f\"300mm Si Wafer {i}\",\n",
    "    \"Organic Substrates\": lambda i: f\"ABF Substrate {i}\",\n",
    "    \"Leadframes\": lambda i: f\"Cu Leadframe QFN-{3+i%5}x{3+i%5} #{i}\",\n",
    "    \"Bonding Wire (Au/Cu)\": lambda i: f\"{'Au' if i%3 else 'Cu'} Wire Ø{0.6 + (i%5)*0.05:.2f}mil #{i}\",\n",
    "    \"Mold Compound\": lambda i: f\"EMC Low-Alpha Grade {i}\",\n",
    "    \"Die Attach Film/Paste\": lambda i: f\"DAF {25 + (i%6)*5}µm #{i}\",\n",
    "    \"Underfill/Epoxy\": lambda i: f\"Capillary Underfill UF-{100 + (i%7)*20} #{i}\",\n",
    "    \"Solder Balls/Spheres\": lambda i: f\"SnAgCu BGA Φ{0.25 + (i%6)*0.05:.2f}mm #{i}\",\n",
    "    \"Probe Cards\": lambda i: f\"MEMS Probe Card {i}\",\n",
    "    \"Test Sockets\": lambda i: f\"BGA Test Socket {0.4 + (i%6)*0.1:.1f}mm pitch #{i}\",\n",
    "    \"Carrier Tapes/Trays\": lambda i: f\"JEDEC Tray {i}\",\n",
    "    \"Nozzles/Capillaries\": lambda i: f\"Bond Capillary ID{30 + (i%8)*5}µm #{i}\",\n",
    "}\n",
    "\n",
    "# Target total SKUs (within the 200–300 range from the plan)\n",
    "TOTAL_SKUS = 240\n",
    "\n",
    "# Allocate SKUs roughly proportional to category importance/cost impact\n",
    "weights = np.array([10, 24, 20, 18, 16, 16, 14, 20, 4, 10, 24, 14], dtype=float)\n",
    "weights = weights / weights.sum()\n",
    "allocations = (weights * TOTAL_SKUS).round().astype(int)\n",
    "\n",
    "# Adjust to hit exactly TOTAL_SKUS\n",
    "diff = TOTAL_SKUS - allocations.sum()\n",
    "for k in range(abs(diff)):\n",
    "    allocations[k % len(allocations)] += 1 if diff > 0 else -1\n",
    "\n",
    "rows = []\n",
    "comp_counter = 1\n",
    "for (cat, cost_rng, lt_rng), count in zip(CATEGORY_SPECS, allocations):\n",
    "    for i in range(count):\n",
    "        unit_cost = float(np.round(np.random.uniform(*cost_rng), 2))\n",
    "        # Add mild log-normal noise to lead time to reflect variability\n",
    "        base_lt = np.random.uniform(*lt_rng)\n",
    "        lt_noise = np.random.lognormal(mean=0.0, sigma=0.15)\n",
    "        lead_time_days = int(max(7, round(base_lt * lt_noise)))\n",
    "\n",
    "        name_fn = NAME_TEMPLATES[cat]\n",
    "        component_name = name_fn(i + 1)\n",
    "\n",
    "        rows.append({\n",
    "            \"component_id\": f\"C{comp_counter:04d}\",\n",
    "            \"component_name\": component_name,\n",
    "            \"category\": cat,\n",
    "            \"unit_cost_usd\": unit_cost,\n",
    "            \"lead_time_days\": lead_time_days\n",
    "        })\n",
    "        comp_counter += 1\n",
    "\n",
    "components_df = pd.DataFrame(rows)\n",
    "\n",
    "# Basic sanity checks: ranges and duplicates\n",
    "assert components_df[\"component_id\"].is_unique, \"component_id must be unique\"\n",
    "assert components_df[\"unit_cost_usd\"].gt(0).all(), \"unit_cost_usd must be positive\"\n",
    "assert components_df[\"lead_time_days\"].ge(7).all(), \"lead_time_days must be >= 7 days\"\n",
    "\n",
    "# Save for downstream use\n",
    "components_df.to_csv(\"components.csv\", index=False)\n",
    "\n",
    "print(\" Components BOM generated:\", components_df.shape[0], \"rows -> components.csv\")\n",
    "print(components_df.sample(8, random_state=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2862de2",
   "metadata": {},
   "source": [
    "###  Generate Realistic Delivery Logs (orders, ETAs, actual receipts)\n",
    "\n",
    "1. Creates delivery_logs with realistic order/expected/actual dates and quantities.\n",
    "    - Reads suppliers.csv and components.csv from prior steps.\n",
    "    - Expected delivery = order_date + component lead time (days).\n",
    "    - Actual delivery reflects delays driven by supplier on-time ratings & randomness.\n",
    "    - Quantities scale by component category; partial receipts & shorts included.\n",
    "    - ~2% missing actual_delivery_date to mimic real-world data gaps.\n",
    "    - Output: delivery_logs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f11aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Delivery logs generated: 9,650 rows -> delivery_logs.csv\n",
      "     delivery_id supplier_id component_id  order_date expected_delivery_date  \\\n",
      "8668    D0008669        S001        C0212  2024-02-19             2024-03-03   \n",
      "2175    D0002176        S015        C0052  2024-02-19             2024-03-21   \n",
      "449     D0000450        S005        C0018  2024-02-19             2024-03-25   \n",
      "498     D0000499        S008        C0019  2024-02-19             2024-04-08   \n",
      "7347    D0007348        S016        C0170  2024-02-19             2024-03-11   \n",
      "2505    D0002506        S016        C0058  2024-02-19             2024-03-22   \n",
      "9304    D0009305        S004        C0229  2024-02-19             2024-03-19   \n",
      "7713    D0007714        S015        C0184  2024-02-19             2024-05-06   \n",
      "\n",
      "     actual_delivery_date  quantity_ordered  quantity_received delivery_status  \n",
      "8668           2024-03-04             15347              15347         Delayed  \n",
      "2175           2024-03-21             19149              19149         On-Time  \n",
      "449            2024-03-25              5525               5525         On-Time  \n",
      "498            2024-04-09              8919               8919         Delayed  \n",
      "7347           2024-03-12             16632              16632         Delayed  \n",
      "2505           2024-03-22             10619              10619         On-Time  \n",
      "9304           2024-03-20               529                529         Delayed  \n",
      "7713           2024-05-06               248                248         On-Time  \n"
     ]
    }
   ],
   "source": [
    "# ---------- Config ----------\n",
    "np.random.seed(7)\n",
    "\n",
    "# Simulation horizon (18 months back from today)\n",
    "END_DATE = pd.Timestamp.today().normalize()\n",
    "START_DATE = END_DATE - pd.DateOffset(months=18)\n",
    "\n",
    "# Order intensity per category (relative weekly volume)\n",
    "CATEGORY_QTY_SCALE = {\n",
    "    \"Silicon Wafers\": 50,\n",
    "    \"Organic Substrates\": 4000,\n",
    "    \"Leadframes\": 12000,\n",
    "    \"Bonding Wire (Au/Cu)\": 8000,\n",
    "    \"Mold Compound\": 3000,\n",
    "    \"Die Attach Film/Paste\": 2500,\n",
    "    \"Underfill/Epoxy\": 2200,\n",
    "    \"Solder Balls/Spheres\": 20000,\n",
    "    \"Probe Cards\": 6,\n",
    "    \"Test Sockets\": 80,\n",
    "    \"Carrier Tapes/Trays\": 15000,\n",
    "    \"Nozzles/Capillaries\": 300\n",
    "}\n",
    "\n",
    "# Weekly order probability by category (how often we place orders)\n",
    "CATEGORY_ORDER_PROB = {\n",
    "    \"Silicon Wafers\": 0.25,\n",
    "    \"Organic Substrates\": 0.65,\n",
    "    \"Leadframes\": 0.7,\n",
    "    \"Bonding Wire (Au/Cu)\": 0.6,\n",
    "    \"Mold Compound\": 0.5,\n",
    "    \"Die Attach Film/Paste\": 0.45,\n",
    "    \"Underfill/Epoxy\": 0.45,\n",
    "    \"Solder Balls/Spheres\": 0.7,\n",
    "    \"Probe Cards\": 0.08,\n",
    "    \"Test Sockets\": 0.2,\n",
    "    \"Carrier Tapes/Trays\": 0.55,\n",
    "    \"Nozzles/Capillaries\": 0.35\n",
    "}\n",
    "\n",
    "# ---------- Load prior artifacts ----------\n",
    "suppliers = pd.read_csv(\"suppliers.csv\")\n",
    "components = pd.read_csv(\"components.csv\")\n",
    "\n",
    "# Ensure expected columns exist\n",
    "assert {\"supplier_id\",\"tier_level\",\"on_time_rating\"}.issubset(suppliers.columns)\n",
    "assert {\"component_id\",\"category\",\"lead_time_days\"}.issubset(components.columns)\n",
    "\n",
    "# Helper: pick a supplier (bias Tier 1 slightly, but allow Tier 2)\n",
    "tier_weight = suppliers[\"tier_level\"].map({\"Tier 1\": 1.3, \"Tier 2\": 0.7}).fillna(1.0)\n",
    "supplier_probs = tier_weight / tier_weight.sum()\n",
    "\n",
    "# Build a weekly calendar; orders are generated on random weekdays\n",
    "weeks = pd.date_range(START_DATE, END_DATE, freq=\"W-MON\")\n",
    "\n",
    "rows = []\n",
    "delivery_counter = 1\n",
    "\n",
    "for _, comp in components.iterrows():\n",
    "    cat = comp[\"category\"]\n",
    "    comp_id = comp[\"component_id\"]\n",
    "    base_qty = CATEGORY_QTY_SCALE.get(cat, 1000)\n",
    "    order_prob = CATEGORY_ORDER_PROB.get(cat, 0.4)\n",
    "\n",
    "    # Determine how many weeks we place orders for this component\n",
    "    for wk_start in weeks:\n",
    "        if np.random.rand() > order_prob:\n",
    "            continue\n",
    "\n",
    "        # Randomize intra-week order day\n",
    "        order_date = wk_start + pd.Timedelta(days=int(np.random.randint(0, 5)))\n",
    "\n",
    "        # Choose supplier with weighted probability\n",
    "        idx = np.random.choice(suppliers.index, p=supplier_probs.values)\n",
    "        sup = suppliers.loc[idx]\n",
    "\n",
    "        # Expected delivery = order + component lead time (+/- small planning jitter)\n",
    "        lead = int(comp[\"lead_time_days\"])\n",
    "        plan_jitter = int(np.random.normal(loc=0, scale=max(2, lead * 0.05)))\n",
    "        expected_delivery_date = order_date + pd.Timedelta(days=max(1, lead + plan_jitter))\n",
    "\n",
    "        # Actual delivery delay driven by on-time rating (lower rating -> more delay)\n",
    "        # Convert rating (85-99%) to delay distribution\n",
    "        rating = float(sup[\"on_time_rating\"])\n",
    "        # Mean extra delay increases as rating drops; add occasional severe tails\n",
    "        mean_delay = max(0, (95 - rating) * 0.6)  # days\n",
    "        extra_delay = np.random.lognormal(mean=np.log(1 + mean_delay/5 + 1e-6), sigma=0.35) - 1\n",
    "        # Rare long-tail disruptions\n",
    "        if np.random.rand() < 0.03:\n",
    "            extra_delay += np.random.randint(5, 21)\n",
    "\n",
    "        delay_days = int(round(max(0, extra_delay)))\n",
    "        actual_delivery_date = expected_delivery_date + pd.Timedelta(days=delay_days)\n",
    "\n",
    "        # Quantity ordered: lognormal around base with moderate variance, min 1\n",
    "        qty_ordered = int(max(1, np.random.lognormal(mean=np.log(max(1, base_qty)), sigma=0.5)))\n",
    "\n",
    "        # Partial receipts/shorts (5% chance), else full receipt\n",
    "        if np.random.rand() < 0.05:\n",
    "            short_ratio = np.clip(np.random.beta(2, 10), 0.02, 0.25)\n",
    "            qty_received = int(max(0, round(qty_ordered * (1 - short_ratio))))\n",
    "        else:\n",
    "            qty_received = qty_ordered\n",
    "\n",
    "        # Status from schedule adherence\n",
    "        if pd.isna(actual_delivery_date):\n",
    "            delivery_status = \"Unknown\"\n",
    "        elif actual_delivery_date > expected_delivery_date:\n",
    "            delivery_status = \"Delayed\"\n",
    "        elif qty_received < qty_ordered:\n",
    "            delivery_status = \"Partial\"\n",
    "        else:\n",
    "            delivery_status = \"On-Time\"\n",
    "\n",
    "        rows.append({\n",
    "            \"delivery_id\": f\"D{delivery_counter:07d}\",\n",
    "            \"supplier_id\": sup[\"supplier_id\"],\n",
    "            \"component_id\": comp_id,\n",
    "            \"order_date\": order_date.date(),\n",
    "            \"expected_delivery_date\": expected_delivery_date.date(),\n",
    "            \"actual_delivery_date\": actual_delivery_date.date(),\n",
    "            \"quantity_ordered\": qty_ordered,\n",
    "            \"quantity_received\": qty_received,\n",
    "            \"delivery_status\": delivery_status\n",
    "        })\n",
    "        delivery_counter += 1\n",
    "\n",
    "# Assemble DataFrame\n",
    "dl = pd.DataFrame(rows)\n",
    "\n",
    "# Inject ~2% missing actual_delivery_date to emulate data gaps\n",
    "mask_missing = np.random.rand(len(dl)) < 0.02\n",
    "dl.loc[mask_missing, \"actual_delivery_date\"] = pd.NaT\n",
    "dl.loc[mask_missing, \"delivery_status\"] = \"Unknown\"\n",
    "\n",
    "# Light sanity checks\n",
    "assert dl[\"quantity_ordered\"].ge(1).all(), \"quantity_ordered must be >= 1\"\n",
    "assert set([\"On-Time\",\"Delayed\",\"Partial\",\"Unknown\"]).issuperset(set(dl[\"delivery_status\"].unique()))\n",
    "\n",
    "# Save\n",
    "dl.sort_values(\"order_date\", inplace=True)\n",
    "dl.to_csv(\"delivery_logs.csv\", index=False)\n",
    "\n",
    "print(f\" Delivery logs generated: {len(dl):,} rows -> delivery_logs.csv\")\n",
    "print(dl.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f899bd",
   "metadata": {},
   "source": [
    "### Simulate Daily Inventory Levels with Stock‑In/Stock‑Out Events\n",
    "\n",
    "\n",
    "1. Generates daily inventory per component using:\n",
    "    - Deliveries from delivery_logs (stock_in on actual_delivery_date)\n",
    "    - Stochastic daily consumption (stock_out) by component category\n",
    "    - Safety stock heuristic to initialize opening balances\n",
    "\n",
    "Output schema: date, component_id, opening_stock, stock_in, stock_out, closing_stock\n",
    "- File: inventory_levels.csv\n",
    "\n",
    "2. Notes:\n",
    "    - Uses category-based demand rates (aligned with our delivery log scales).\n",
    "    - Introduces realistic demand spikes and occasional negative balances (rare), which we will clean in Task 2 (data quality issues).\n",
    "    - Produces ~130–150k rows (e.g., ~240 components × ~540 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6165bc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inventory levels generated: 151,200 rows -> inventory_levels.csv\n",
      "         date component_id  opening_stock  stock_in  stock_out  closing_stock\n",
      "0  2024-02-19        C0001            162         0         10            152\n",
      "1  2024-02-20        C0001            152         0          2            150\n",
      "2  2024-02-21        C0001            150         0          4            146\n",
      "3  2024-02-22        C0001            146         0         11            135\n",
      "4  2024-02-23        C0001            135         0          5            130\n",
      "5  2024-02-24        C0001            130         0          3            127\n",
      "6  2024-02-25        C0001            127         0         12            115\n",
      "7  2024-02-26        C0001            115         0          7            108\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "\n",
    "# ---------- Load prior artifacts ----------\n",
    "components = pd.read_csv(\"components.csv\")\n",
    "deliveries = pd.read_csv(\n",
    "    \"delivery_logs.csv\",\n",
    "    parse_dates=[\"order_date\", \"expected_delivery_date\", \"actual_delivery_date\"]\n",
    ")\n",
    "\n",
    "# Build simulation calendar\n",
    "start_date = min(\n",
    "    deliveries[\"order_date\"].min(),\n",
    "    deliveries[\"actual_delivery_date\"].min(skipna=True)\n",
    ")\n",
    "end_date = max(\n",
    "    deliveries[\"expected_delivery_date\"].max(),\n",
    "    deliveries[\"actual_delivery_date\"].max(skipna=True)\n",
    ")\n",
    "calendar = pd.date_range(start_date, end_date, freq=\"D\")\n",
    "\n",
    "# Category baseline: weekly -> daily demand\n",
    "CATEGORY_QTY_SCALE_WEEKLY = {\n",
    "    \"Silicon Wafers\": 50,\n",
    "    \"Organic Substrates\": 4000,\n",
    "    \"Leadframes\": 12000,\n",
    "    \"Bonding Wire (Au/Cu)\": 8000,\n",
    "    \"Mold Compound\": 3000,\n",
    "    \"Die Attach Film/Paste\": 2500,\n",
    "    \"Underfill/Epoxy\": 2200,\n",
    "    \"Solder Balls/Spheres\": 20000,\n",
    "    \"Probe Cards\": 6,\n",
    "    \"Test Sockets\": 80,\n",
    "    \"Carrier Tapes/Trays\": 15000,\n",
    "    \"Nozzles/Capillaries\": 300\n",
    "}\n",
    "CATEGORY_DAILY_BASE = {k: max(1, v/7) for k, v in CATEGORY_QTY_SCALE_WEEKLY.items()}\n",
    "\n",
    "# Pre-aggregate deliveries by component & date\n",
    "inbound = (\n",
    "    deliveries\n",
    "    .dropna(subset=[\"actual_delivery_date\"])\n",
    "    .assign(date=lambda df: df[\"actual_delivery_date\"].dt.date)  # ensure date column exists\n",
    "    .groupby([\"component_id\", \"date\"], as_index=False)[\"quantity_received\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"quantity_received\": \"stock_in\"})\n",
    ")\n",
    "\n",
    "# Prepare per-component demand parameters\n",
    "comp_meta = components[[\"component_id\", \"category\", \"lead_time_days\"]].copy()\n",
    "comp_meta[\"daily_base\"] = comp_meta[\"category\"].map(CATEGORY_DAILY_BASE).astype(float)\n",
    "\n",
    "rng = np.random.default_rng(11)\n",
    "comp_meta[\"demand_multiplier\"] = rng.normal(loc=1.0, scale=0.25, size=len(comp_meta)).clip(0.5, 1.6)\n",
    "comp_meta[\"daily_demand_mu\"] = (comp_meta[\"daily_base\"] * comp_meta[\"demand_multiplier\"]).clip(0.5, None)\n",
    "\n",
    "# Safety stock heuristic\n",
    "comp_meta[\"safety_stock\"] = np.ceil(\n",
    "    comp_meta[\"daily_demand_mu\"] * rng.integers(10, 17, size=len(comp_meta)) *\n",
    "    (1 + (comp_meta[\"lead_time_days\"]/90).clip(0, 0.6))\n",
    ").astype(int)\n",
    "\n",
    "# Inject occasional negative initial stock (data quality issue)\n",
    "glitch_mask = rng.random(len(comp_meta)) < 0.01\n",
    "comp_meta.loc[glitch_mask, \"safety_stock\"] *= -1\n",
    "\n",
    "daily_mu = dict(zip(comp_meta[\"component_id\"], comp_meta[\"daily_demand_mu\"]))\n",
    "safety_stock = dict(zip(comp_meta[\"component_id\"], comp_meta[\"safety_stock\"]))\n",
    "\n",
    "# Build inventory ledger\n",
    "records = []\n",
    "for comp_id in comp_meta[\"component_id\"]:\n",
    "    opening = int(safety_stock[comp_id])\n",
    "\n",
    "    comp_inbound = inbound[inbound[\"component_id\"] == comp_id]\n",
    "    inbound_by_date = dict(zip(comp_inbound[\"date\"], comp_inbound[\"stock_in\"]))\n",
    "\n",
    "    spike_days = set(np.random.choice(calendar.date, size=max(3, int(0.02*len(calendar))), replace=False))\n",
    "\n",
    "    for dt in calendar:\n",
    "        date_key = dt.date()\n",
    "        stock_in = int(inbound_by_date.get(date_key, 0))\n",
    "\n",
    "        mu = max(0.5, daily_mu[comp_id])\n",
    "        base_out = np.random.poisson(mu)\n",
    "\n",
    "        if date_key in spike_days:\n",
    "            spike_mult = np.random.uniform(1.5, 3.0)\n",
    "        else:\n",
    "            spike_mult = np.random.normal(1.0, 0.10)\n",
    "\n",
    "        stock_out = int(max(0, round(base_out * max(0.2, spike_mult))))\n",
    "        closing = opening + stock_in - stock_out\n",
    "\n",
    "        records.append({\n",
    "            \"date\": date_key,\n",
    "            \"component_id\": comp_id,\n",
    "            \"opening_stock\": int(opening),\n",
    "            \"stock_in\": int(stock_in),\n",
    "            \"stock_out\": int(stock_out),\n",
    "            \"closing_stock\": int(closing)\n",
    "        })\n",
    "\n",
    "        opening = closing\n",
    "\n",
    "inv = pd.DataFrame(records)\n",
    "inv.sort_values([\"component_id\", \"date\"], inplace=True)\n",
    "inv.to_csv(\"inventory_levels.csv\", index=False)\n",
    "\n",
    "print(f\" Inventory levels generated: {len(inv):,} rows -> inventory_levels.csv\")\n",
    "print(inv.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2037f",
   "metadata": {},
   "source": [
    "### Generate Production Orders with Daily Spikes (consistent with inventory usage)\n",
    "\n",
    "This script creates production_orders that are *consistent* with previously simulated inventory movements. We treat the inventory \"stock_out\" as the ACTUAL issued quantity (units_issued). Then, we simulate higher \"units_required\" on spike days to create unmet demand/backorders when inventory is tight (e.g., closing_stock <= 0).\n",
    "\n",
    "- Output schema:\n",
    "prod_order_id, date, component_id, units_required, units_issued\n",
    "\n",
    "- File: production_orders.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5c0f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production orders generated: 151,200 rows -> production_orders.csv\n",
      "  prod_order_id        date component_id  units_required  units_issued\n",
      "0    PO00000001  2024-02-19        C0001              10            10\n",
      "1    PO00000002  2024-02-20        C0001               2             2\n",
      "2    PO00000003  2024-02-21        C0001               4             4\n",
      "3    PO00000004  2024-02-22        C0001              12            11\n",
      "4    PO00000005  2024-02-23        C0001               5             5\n",
      "5    PO00000006  2024-02-24        C0001               3             3\n",
      "6    PO00000007  2024-02-25        C0001              12            12\n",
      "7    PO00000008  2024-02-26        C0001               8             7\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "\n",
    "# Load prior artifacts\n",
    "inv = pd.read_csv(\"inventory_levels.csv\", parse_dates=[\"date\"])\n",
    "components = pd.read_csv(\"components.csv\")\n",
    "\n",
    "# Merge category into inventory for spike behavior\n",
    "inv = inv.merge(\n",
    "    components[[\"component_id\", \"category\"]],\n",
    "    on=\"component_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Prepare spike days for each component\n",
    "per_comp_spikes = {}\n",
    "for comp_id, comp_df in inv.groupby(\"component_id\", sort=False):\n",
    "    unique_dates = np.sort(comp_df[\"date\"].unique())  # FIX: np.sort to avoid AttributeError\n",
    "    n_days = len(unique_dates)\n",
    "    n_spikes = max(3, int(0.02 * n_days))\n",
    "    spike_idx = np.random.choice(n_days, size=n_spikes, replace=False)\n",
    "    spike_days = set(pd.to_datetime(unique_dates[spike_idx]).date)\n",
    "    per_comp_spikes[comp_id] = spike_days\n",
    "\n",
    "# Category-level spike intensity tuning\n",
    "CATEGORY_SPIKE_MULT = {\n",
    "    \"Silicon Wafers\": (1.3, 1.8),\n",
    "    \"Organic Substrates\": (1.4, 2.1),\n",
    "    \"Leadframes\": (1.4, 2.2),\n",
    "    \"Bonding Wire (Au/Cu)\": (1.3, 1.9),\n",
    "    \"Mold Compound\": (1.3, 1.9),\n",
    "    \"Die Attach Film/Paste\": (1.3, 2.0),\n",
    "    \"Underfill/Epoxy\": (1.3, 2.0),\n",
    "    \"Solder Balls/Spheres\": (1.5, 2.4),\n",
    "    \"Probe Cards\": (1.1, 1.4),\n",
    "    \"Test Sockets\": (1.2, 1.6),\n",
    "    \"Carrier Tapes/Trays\": (1.5, 2.3),\n",
    "    \"Nozzles/Capillaries\": (1.2, 1.7)\n",
    "}\n",
    "\n",
    "records = []\n",
    "counter = 1\n",
    "\n",
    "for row in inv.itertuples(index=False):\n",
    "    comp_id = row.component_id\n",
    "    dt = row.date.date()\n",
    "    cat = row.category\n",
    "    issued = int(max(0, row.stock_out))\n",
    "\n",
    "    # Base variation\n",
    "    base_mult = np.random.normal(loc=1.0, scale=0.08)\n",
    "    base_mult = max(0.85, min(1.25, base_mult))\n",
    "\n",
    "    # Spike multiplier\n",
    "    spike_low, spike_high = CATEGORY_SPIKE_MULT.get(cat, (1.25, 1.9))\n",
    "    if dt in per_comp_spikes.get(comp_id, set()):\n",
    "        spike_mult = np.random.uniform(spike_low, spike_high)\n",
    "    else:\n",
    "        spike_mult = 1.0\n",
    "\n",
    "    # Units required and unmet demand\n",
    "    rough_required = int(max(issued, round(issued * base_mult * spike_mult)))\n",
    "    if row.closing_stock <= 0:\n",
    "        unmet = int(np.random.poisson(lam=max(1, issued * 0.25)))\n",
    "    else:\n",
    "        unmet = int(np.random.binomial(n=max(0, issued), p=0.03))\n",
    "\n",
    "    units_required = rough_required + unmet\n",
    "\n",
    "    records.append({\n",
    "        \"prod_order_id\": f\"PO{counter:08d}\",\n",
    "        \"date\": dt,\n",
    "        \"component_id\": comp_id,\n",
    "        \"units_required\": int(units_required),\n",
    "        \"units_issued\": int(issued)\n",
    "    })\n",
    "    counter += 1\n",
    "\n",
    "po = pd.DataFrame(records)\n",
    "po.sort_values([\"component_id\", \"date\"], inplace=True)\n",
    "po.to_csv(\"production_orders.csv\", index=False)\n",
    "\n",
    "print(f\"Production orders generated: {len(po):,} rows -> production_orders.csv\")\n",
    "print(po.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ddc18",
   "metadata": {},
   "source": [
    "### Generate Monthly Demand Forecasts with ±20–40% Variation\n",
    "\n",
    "1. Creates forecasts.csv using actual monthly demand (units_required from production_orders)\n",
    "2. Adds realistic forecast error of ±20–40% (both over- and under-estimation)\n",
    "3. Output schema: month (YYYY-MM), component_id, forecast_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658a9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasts generated: 5,280 rows -> forecasts.csv\n",
      "        month component_id  forecast_units\n",
      "4445  2025-08        C0126           19576\n",
      "4139  2025-07        C0060           74500\n",
      "3707  2025-05        C0108           22253\n",
      "1010  2024-06        C0051           64578\n",
      "722   2024-05        C0003             268\n",
      "4648  2025-09        C0089           55860\n",
      "3870  2025-06        C0031           22757\n",
      "1684  2024-09        C0005             346\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(33)\n",
    "\n",
    "# Load production orders\n",
    "po = pd.read_csv(\"production_orders.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Aggregate actual monthly demand per component\n",
    "po[\"month\"] = po[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "monthly_demand = (\n",
    "    po.groupby([\"month\", \"component_id\"], as_index=False)[\"units_required\"]\n",
    "      .sum()\n",
    "      .rename(columns={\"units_required\": \"actual_units\"})\n",
    ")\n",
    "\n",
    "# Apply forecast variation: ±20–40%\n",
    "# Positive error = overestimate, negative = underestimate\n",
    "variation_pct = np.random.uniform(-0.4, 0.4, size=len(monthly_demand))\n",
    "monthly_demand[\"forecast_units\"] = (\n",
    "    monthly_demand[\"actual_units\"] * (1 + variation_pct)\n",
    ").round().astype(int)\n",
    "\n",
    "# Avoid zero or negative forecasts (set a min of 1 unit)\n",
    "monthly_demand[\"forecast_units\"] = monthly_demand[\"forecast_units\"].clip(lower=1)\n",
    "\n",
    "# Save only required forecast columns\n",
    "forecasts = monthly_demand[[\"month\", \"component_id\", \"forecast_units\"]]\n",
    "forecasts.to_csv(\"forecasts.csv\", index=False)\n",
    "\n",
    "print(f\"Forecasts generated: {len(forecasts):,} rows -> forecasts.csv\")\n",
    "print(forecasts.sample(8, random_state=7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
